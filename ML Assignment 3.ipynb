{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog, simpledialog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pandas import read_csv\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CATH\n",
    "\n",
    "def scale_and_encode(df):\n",
    "\n",
    "    # Get Features\n",
    "    # if features are continuous - revisit\n",
    "    feats = df.drop(df.columns[[-1]], axis=1).apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "    # Get encoded Labels\n",
    "    labels = pd.get_dummies(df[df.columns[-1:]])\n",
    "\n",
    "    # Recombine feats & labels\n",
    "    combine_data = pd.concat([feats, labels], axis=1)\n",
    "    \n",
    "    return combine_data, len(feats.columns)\n",
    "\n",
    "\n",
    "#Gets data in the correct format and adds a bias to the features\n",
    "def feat_label_bias(df, label_ind):\n",
    "\n",
    "    list_data_pre = df.values.tolist()\n",
    "    list_data = [[x[0:label_ind] + [1.0] for x in list_data_pre]] + [[x[label_ind:] for x in list_data_pre]]\n",
    "    \n",
    "    new_df = pd.DataFrame(data=list_data).transpose()\n",
    "    new_df.columns = ['feats', 'labels']\n",
    "\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Andrew\n",
    "\n",
    "def load_file(filename, names):\n",
    "    \"\"\" Loads a csv into a dataframe\"\"\"\n",
    "    \n",
    "    print(filename)\n",
    "    data = read_csv(filename, names=names) \n",
    "    return data\n",
    "\n",
    "\n",
    "def train_test_split(data, train_frac=0.666):\n",
    "    \"\"\" Takes a dataset and splits it into a training and test set with measures to ensure even distribution\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    data -- pandas dataframe of data to be split\n",
    "    train_frac -- franction of the data to be used for training, the rest will be used for test\n",
    "    \n",
    "    N.B: The feature labes must be the last column in the dataset\"\"\"\n",
    "    \n",
    "    labels = data[data.columns[-1]] # get last column in dataframe which will contain labels\n",
    "    num_labels = len(labels.unique())\n",
    "    split_threshold = 1/num_labels\n",
    "    \n",
    "    train = data.sample(frac=train_frac, random_state=np.random.RandomState())\n",
    "    test = data.drop(train.index)\n",
    "\n",
    "    unique_labels = labels.unique()\n",
    "  \n",
    "    label_splits_train = [sum(train[train.columns[-1]] == x) for x in unique_labels]\n",
    "    label_splits_test = [sum(test[test.columns[-1]] == x) for x in unique_labels]   \n",
    "    \n",
    "    split_vals_train = [x/len(train) for x in label_splits_train]\n",
    "    split_vals_test = [x/len(test) for x in label_splits_test]\n",
    "    \n",
    "    is_even_split_train = [(split_val < (split_threshold + 0.1)) & (split_val > (split_threshold - 0.1))\n",
    "                           for split_val in split_vals_train] # Ensure a fair split \n",
    "    is_even_split_test = [(split_val < (split_threshold + 0.1)) & (split_val > (split_threshold - 0.1))\n",
    "                           for split_val in split_vals_test]\n",
    "    \n",
    "    if not is_even_split_train and not is_even_split_test:\n",
    "        return train_test_split(data, train_frac)\n",
    "    else:\n",
    "        return train, test\n",
    "    \n",
    "    #split_val: decimal representation of how much one type makes up of the while data set\n",
    "    #split_threshold: how much each of the labels should represent in the data set\n",
    "    \n",
    "    \n",
    "def rand_train_test_split(data, train_frac=0.666):\n",
    "    \"\"\" Takes a dataset and splits it into a training and test set\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    data -- pandas dataframe of data to be split\n",
    "    train_frac -- franction of the data to be used for training, the rest will be used for test\n",
    "    \n",
    "    N.B: The feature labes must be the last column in the dataset\"\"\"\n",
    "    \n",
    "    labels = data[data.columns[-1]] # get last column in dataframe which will contain labels\n",
    "    \n",
    "    sample_size = int(len(data)*train_frac)\n",
    "    \n",
    "    train = data.sample(frac=train_frac, random_state=np.random.RandomState())\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def n_random_split(n, data, splitter=rand_train_test_split):\n",
    "    \"\"\" Takes a pandas dataframe and returns n amount of random splits of training and test data in a dict\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    n -- number of training/test sets to return\n",
    "    data -- dataframe to split \n",
    "    splitter -- function which splits the data into train and test\"\"\"\n",
    "    \n",
    "    d = {}\n",
    "    for i in range(n):\n",
    "        train, test = splitter(data)\n",
    "        d[i] = [train, test]\n",
    "        \n",
    "    return d\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Header interferes with names - investigate later\n",
    "headerFlag = None\n",
    "delimFlag = ','\n",
    "namesFlag = ['att1', 'att2', 'att3', 'att4', 'OwlLabel']\n",
    "# body-length, wing-length, body-width, wing-width, type.\n",
    "\n",
    "labelColumn = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(data):\n",
    "    print('')\n",
    "\n",
    "    \n",
    "def predict():\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_closing():\n",
    "    root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/AMCBR/MyStuff/College Notes & Work/Year 4/Machine Learning & Data Mining/Assignment 3/owls15.csv\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "filename = filedialog.askopenfilename(filetypes=((\"CSV\", \"*.csv\")\n",
    "                                                     , (\"All files\", \"*.*\")))\n",
    "names=[\"body-length\", \"wing-length\", \"body-width\", \"wing-width\", \"type\"]\n",
    "data = load_file(filename, names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "\n",
    "train, test = rand_train_test_split(data, 0.666)\n",
    "d = n_random_split(10, data)\n",
    "##############################################\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d is a dictionary containing the index 0 though n-1.\\n For each index there is a list called datasets containing \\n a training set at datasets[0] and a test set at datasets[1]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, datasets in d.items():\n",
    "    train_data = datasets[0]\n",
    "    test_data = datasets[1]\n",
    "   \n",
    "    \n",
    "\"\"\"d is a dictionary containing the index 0 though n-1.\n",
    " For each index there is a list called datasets containing \n",
    " a training set at datasets[0] and a test set at datasets[1]\"\"\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Function Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: train_test_split\n",
      "Passed: True\n",
      "\n",
      "Test: rand_train_test_split\n",
      "Passed: True\n",
      "\n",
      "Test: n_random_split\n",
      "Passed: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 5\n",
    "# data1 = pd.DataFrame(np.random.randint(0,dataset_size,size=(dataset_size, 4)), columns=list('ABCD'))\n",
    "# data1.loc[:,'E'] = pd.Series(np.random.randint(1,3, size=(dataset_size)), index=data1.index)\n",
    "row1=[4, 2, 3, 0, 1]\n",
    "row2=[4, 2, 0, 0, 2]\n",
    "row3=[1, 1, 2, 0, 2]\n",
    "row4=[0, 4, 4, 1, 1]\n",
    "row5=[1, 2, 4, 2, 1]\n",
    "\n",
    "data1 = pd.DataFrame(\n",
    "    {\n",
    "        \"1\": row1,\n",
    "        \"2\": row2,\n",
    "        \"3\": row3,\n",
    "        \"4\": row4,\n",
    "        \"5\": row5\n",
    "    })\n",
    "\n",
    "size = len(data1)\n",
    "passed = False\n",
    "\n",
    "####Test: train_test_split\n",
    "print('Test: train_test_split')\n",
    "frac=0.666\n",
    "train, test = train_test_split(data1, train_frac=frac)\n",
    "correct_size = (len(train)+len(test) == size)\n",
    "correct_split = (frac+0.1 > len(train)/size > frac-0.1 ) \n",
    "\n",
    "passed = correct_size and correct_split\n",
    "print('Passed: {}'.format(passed))\n",
    "\n",
    "\n",
    "\n",
    "####Test: rand_train_test_split\n",
    "print('\\nTest: rand_train_test_split')\n",
    "frac=0.666\n",
    "train, test = rand_train_test_split(data1, train_frac=frac)\n",
    "correct_size = (len(train)+len(test) == size)\n",
    "correct_split = (frac+0.1 > len(train)/size > frac-0.1 ) \n",
    "\n",
    "passed = correct_size and correct_split\n",
    "print('Passed: {}'.format(passed))\n",
    "\n",
    "\n",
    "\n",
    "###Test: n_random_split\n",
    "print('\\nTest: n_random_split')\n",
    "d = n_random_split(10, data1)\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "comparison =[]\n",
    "for key, val in d.items():\n",
    "    train_sets.append(val[0])\n",
    "    test_sets.append(val[1])\n",
    "    \n",
    "for i, j in itertools.combinations(train_sets, 2):\n",
    "    comparison.append(i.equals(j))\n",
    "      \n",
    "passed = not any(comparison)\n",
    "print('Passed: {}'.format(passed))\n",
    "\n",
    "\n",
    "\n",
    "#####Test: scale_and_encode#####\n",
    "row1=[0.50,0.6,-0.1,-0.50]\n",
    "row2=[0.00,0.1,-0.1,0.50]\n",
    "row3=[0.25,-0.4,0.4,0.50]\n",
    "row4=[-0.50,-0.4,-0.6,-0.25]\n",
    "row5=[-0.25,0.1,0.4,-0.25]\n",
    "##fix\n",
    "s_data = pd.DataFrame(\n",
    "    {\n",
    "        \"0\": row1,\n",
    "        \"1\": row2,\n",
    "        \"2\": row3,\n",
    "        \"3\": row4,\n",
    "        \"4\": row5\n",
    "    }).transpose()\n",
    "\n",
    "cd, feats = scale_and_encode(data1)\n",
    "\n",
    "s_data.equals(cd.drop(cd.columns[[-1]], axis=1))\n",
    "#####Test: feat_label_bias#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2    3     4\n",
       "0  0.50  0.6 -0.1 -0.50\n",
       "1  0.00  0.1 -0.1  0.50\n",
       "2  0.25 -0.4  0.4  0.50\n",
       "3 -0.50 -0.4 -0.6 -0.25\n",
       "4 -0.25  0.1  0.4 -0.25"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.drop(cd.columns[[-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2     3\n",
       "0  0.50  0.6 -0.1 -0.50\n",
       "1  0.00  0.1 -0.1  0.50\n",
       "2  0.25 -0.4  0.4  0.50\n",
       "3 -0.50 -0.4 -0.6 -0.25\n",
       "4 -0.25  0.1  0.4 -0.25"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##Display Results##\n",
    "root.deiconify()\n",
    "label1=Label(root,text=\"Output\")\n",
    "label1.pack()\n",
    "\n",
    "output_string = 'Successfullly ran through the program with x10 iterations - this has been outputted to results.txt'\n",
    "results = Text (root)\n",
    "results.pack()\n",
    "results.insert(END, output_string)\n",
    "\n",
    "root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
